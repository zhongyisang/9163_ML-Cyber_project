{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Neural Cleanse ",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "***Using the Neural Cleanse method to prune the Badnet***"
      ],
      "metadata": {
        "id": "6v3Xehlfn669"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "import keras.backend as K\n",
        "from keras import initializers\n",
        "\n",
        "\n",
        "def Net():\n",
        "\t# define input\n",
        "\tx = keras.Input(shape=(55, 47, 3), name='input')\n",
        "\t# feature extraction\n",
        "\tconv_1 = keras.layers.Conv2D(20, (4, 4), activation='relu', name='conv_1')(x)\n",
        "\tpool_1 = keras.layers.MaxPooling2D((2, 2), name='pool_1')(conv_1)\n",
        "\tconv_2 = keras.layers.Conv2D(40, (3, 3), activation='relu', name='conv_2')(pool_1)\n",
        "\tpool_2 = keras.layers.MaxPooling2D((2, 2), name='pool_2')(conv_2)\n",
        "\tconv_3 = keras.layers.Conv2D(60, (3, 3), activation='relu', name='conv_3')(pool_2)\n",
        "\tpool_3 = keras.layers.MaxPooling2D((2, 2), name='pool_3')(conv_3)\n",
        "\t# first interpretation model\n",
        "\tflat_1 = keras.layers.Flatten()(pool_3)\t\n",
        "\tfc_1 = keras.layers.Dense(160, name='fc_1')(flat_1)\n",
        "\t# second interpretation model\n",
        "\tconv_4 = keras.layers.Conv2D(80, (2, 2), activation='relu', name='conv_4')(pool_3)\n",
        "\tflat_2 = keras.layers.Flatten()(conv_4)\n",
        "\tfc_2 = keras.layers.Dense(160, name='fc_2')(flat_2)\n",
        "\t# merge interpretation\n",
        "\tmerge = keras.layers.Add()([fc_1, fc_2])\n",
        "\tadd_1 = keras.layers.Activation('relu')(merge)\n",
        "\tdrop = keras.layers.Dropout(0.5)\n",
        "\t# output\n",
        "\ty_hat = keras.layers.Dense(1283, activation='softmax', name='output')(add_1)\n",
        "\tmodel = keras.Model(inputs=x, outputs=y_hat)\n",
        "\t# summarize layers\n",
        "\t#print(model.summary())\n",
        "\t# plot graph\n",
        "\t#plot_model(model, to_file='model_architecture.png')\n",
        "\n",
        "\treturn model\n",
        "\n",
        "\n",
        "K.clear_session()\n",
        "model = Net()"
      ],
      "metadata": {
        "id": "P9NPR3jMoDz2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##Data loader\n",
        "class DataGenerator(object):\n",
        "  def__init__(self,target_ls):\n",
        "    self.target_ls=target_ls\n",
        "  def generate_data(self,X,Y, inject_ratio):\n",
        "    batch_X,batch_Y = [] , []\n",
        "    while 1:\n",
        "      inject_ptr = random.uniform(0,1)\n",
        "      cur_idx = random.randrange(0,len(Y)-1)\n",
        "      cur_x = X[cur_idx]\n",
        "      cur_y = Y[cur_idx]\n",
        "\n",
        "      if inject_ptr < inject_ratio:\n",
        "        tgt = random.choice(self.target_ls)\n",
        "        cur_x,cur_y = infect_X(cur_x,tgt)\n",
        "      \n",
        "      batch_X.append(cur_x)\n",
        "      batch_Y.append(cur_y)\n",
        "\n",
        "      if len(batch_Y) == BATCH_SIZE:\n",
        "        yield np.array(batch_X), np.array(batch_Y)\n",
        "        batch_X.batch_Y = [] , []\n",
        "        \n",
        "\n"
      ],
      "metadata": {
        "id": "joZgOvaQpCjd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##training the model\n",
        "def inject_backdoor():\n",
        "  train_X,train_Y,test_X,test_Y = load_dataset()\n",
        "  model = load_traffic_sign_model()\n",
        "\n",
        "  base_gen =DataGenerator(TARGET_LS)\n",
        "  test_adv_gen = base_gen.generate_data(test_X,test_Y,1)\n",
        "  train_gen = base_gen.generate(train_X,train_Y,INJECT_RATIO)\n",
        "\n",
        "  cb = BackdoorCall(tset_X,test_Y, test_adv_gen)\n",
        "  number_images = NUMBER_IMAGES_RATIO * len(train_Y)\n",
        "  model.fit_generator(train_gen,steps_per_epoch=number_images)\n",
        "\n",
        "  loss, acc =model.evaluate(test_X,test_Y,verbose=0)\n",
        "  loss,backdoor_acc = model.evaluate_generator(test_adv_gen,steps=200,verbose=0)"
      ],
      "metadata": {
        "id": "oijZ5zFzq1SO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##Reverse trigger\n",
        "def visualize_trigger_w_mask(visualizer,gen,y_target,save_pattern_flag=True):\n",
        "  visualize_start_time = time.time()\n",
        "\n",
        "  pattern = np.random.random(INPUT_SHAPE)*255\n",
        "  mask = np.random.random(MASK_SHAPE)\n",
        "\n",
        "  pattern,mask,mask_upsample, logs=visualizer.visualize(\n",
        "      gen=gen,y_target=y_target,pattern_init=pattern, mask_init=mask\n",
        "  )"
      ],
      "metadata": {
        "id": "gsfAX6Kmsr9U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def visualize(self,gen,y_target,pattern_init,mask_init):\n",
        "  self.reset_state(pattern_init,mask_init)\n",
        "  mask_best=None\n",
        "  mask_upsample_best=None\n",
        "  pattern_best = None\n",
        "  reg_best = float('inf')\n",
        "\n",
        "  Y_target= to_categorical([y_target]*self.batch_size,self.num_classes)\n",
        "  for step in range(self.steps):\n",
        "    loss_ce_list=[]\n",
        "    loss_reg_list=[]\n",
        "    loss_list=[]\n",
        "    loss_acc_list = []\n",
        "    for idx in range(self.minibatch):\n",
        "      X_batch,_=gen.next()\n",
        "      if batch.shape[0] != Y_target.shape[0]:\n",
        "        Y_target= to_categorical([y_target]&X_batch.shape[0],self.num_classes)\n",
        "        loss_ce_list.extend(list(loss_ce_value.flatten()))\n",
        "        loss_reg_list.extend(list(loss_reg_value.flatten()))\n",
        "        loss_list.extend(list(loss_value.flatten()))\n",
        "        loss_acc_list.extend(list(loss_acc_value.flatten()))\n",
        "      avg_ce_loss = np.mean(loss_ce_list)\n",
        "      avg_loss_reg = np.mean(loss_reg_list)\n",
        "      avg_loss = np.mean(loss_list)\n",
        "      avg_loss_acc = np.mean(loss_list_acc)\n",
        "\n",
        "      if avg_loss_acc >= self.attack_succ_threshold and avg_loss_reg < reg_best:\n",
        "        mask_best = K.eval(self.mask_tensor)\n",
        "        mask_best = mask_best[0,...,0]\n",
        "        mask_upsample_best = K.eval(self.mask_upsample_tensor)\n",
        "        mask_upsample_best = mask_upsample_best[0,...,0]\n",
        "        pattern_best =K.eval(self.pattern_raw_tensor)\n",
        "        reg_best=avg_loss_reg\n"
      ],
      "metadata": {
        "id": "GZd72GHDtef7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#pattern\n",
        "  img_filename=(\n",
        "      '%s/%s'%(\n",
        "          RESULT_DIR,IMG_FILENAME_TEMPLATE %('pattern',y_target)))\n",
        "  utils_backdoor.dump_image(pattern,img_filename,'png')\n",
        "\n",
        "\n",
        "#mask\n",
        "  img_filename=(\n",
        "      '%s/%s'%(\n",
        "          RESULT_DIR,IMG_FILENAME_TEMPLATE %('mask',y_target)))\n",
        "  utils_backdoor.dump_image(np.expand_dims(mask,axis=2)*255,img_filename,'png')\n",
        "\n",
        "  fusion = np.multiply(pattern,np.expand_dims(mask,axis=2))\n",
        "  img_filename=(\n",
        "      '%s/%s'%(\n",
        "          RESULT_DIR,IMG_FILENAME_TEMPLATE %('fusion',y_target)))\n",
        "  utils_backdoor.dump_image(fusion,img_filename,'png')\n"
      ],
      "metadata": {
        "id": "TNtHwG0BwKl7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}